###

人事部の仕事の中で最も重要であり、組織や社員全体に大きな影響を与えるのが「評価」に関する業務です。
評価対象となるのは個々人のノルマ達成率や、売上額といった実績評価だけではありません。採用はもちろん、異動や昇格の判断、ボーナスの査定、研修の達成度評価まで、ありとあらゆる場面で「評価」する作業が存在します。適切な評価は従業員のモチベーションを高め、組織を活性化させる重要な要素になりますが、評価を誤れば、社内の不信を招き、優秀な人材が離職してしまうこともあるでしょう。会社全体の浮沈を左右する非常に重要な業務です。
では、この重要な評価業務に AI をどう活用すればよいのでしょうか。また活用する際はどんなことに気を付ければよいのでしょうか。
評価業務における AI の「補完的役割」としては、2 通りの活用方法が考えられます。1 つは「評価の基準づくり」を AI に委ねるという手法です。
例えば、採用したい人材のスキルや能力については人事部の担当者が定義した上で、実際にどのような試験を実施し、どういった基準で評価すべきかという仕組みづくりの一部を AI に任せることが考えられるでしょう。
もう 1 つの活用方法は、AI を「評価者のバイアス排除」に使うという考え方です。
採用面接を例に考えてみましょう。ある企業で 2 次面接の面接官を務める F さんは入社 15 年目の課長職です。過去 3 年間で、男女 50 人ずつ計 100 人の面接を担当し、60 人を通過させてきました。
通過者 60 人のうち、男性が 50 人以上を占めていたとしたら、F さんの選考には性別によるバイアスがかかっていると考えてよいのではないでしょうか。
あるいは、通過者に F さんが卒業した大学の後輩にあたる人が際立って多いといったこともあるかもしれません。AI を使えば、こうした評価者の主観や好みによる偏りを検知し、F さん自身にフィードバックしたり、人事部の採用担当者にアラートしたりすることが可能です。
離職防止対策を考える際は、施策一つひとつの良しあしを考えるよりも、まず離職を検討している社員や、離職者が増えている職場を早期に特定し、先手先手で介入していくことが重要です。こうした「離職リスク」の特定において役立つのが、AI が得意とする異常検出機能です。
異常検出機能とは、データセット内で通常とは異なるパターンを特定するために使用される技術を指します。データの正常なパターンを学習し、その知識を基に、新たに入力されたデータが正常な範囲に収まるか、あるいはその範囲を逸脱する「異常パターン」であるかを判断する仕組みです。これを会社に対する社員の満足度調査（エンゲージメントスコア）の評価に応用すれば、「離職の可能性がある人」として特定することができます。もう少し詳しく解説します。
正常なパターンを学習させるためには、一定量のデータを必要としますが、過去 10 年以上にわたって従業員の満足度調査を実施している企業であれば、全体のデータからすでに離職した人のデータを排除することで、自社にとどまった人たち（離職しなかった人たち）だけのデータセットを作ることができます。この人たちの回答結果を「正」とすることで、そこから逸脱した意見や声を異常なパターンとしてピックアップすることが可能になるのです。
離職届を出す半年前、あるいは数カ月前にでも、こうした情報を検知できれば、その社員に個別にヒアリングをしたり、勤務状況を調査したりすることで、それぞれの事情や要望に見合った対応策を検討する時間的余裕が確保できるようになります。
AI の活用本らしくない、やや観念的な話になりますが、社員の離職検討は「業務の改善を提案しても話を聞いてもらえない」「問題を訴えても耳を貸してもらえない」といった組織に対する不信感から始まるケースが少なくありません。離職防止対策を考える上では、AI を使って少しでも早くリスクを検知し、真摯に対応する姿勢を示すことが最も重要だと考えられます。
評価に関係する業務では、最終的な判断を AI に任せることは大きな危険性をはらんでおり、そのリスクはすでに様々な場面で指摘されています。EU（欧州連合）では、個人情報保護について定められた法律の中で、採用活動における AI の活用について、企業側に説明責任を果たすよう求めるルールが定められています。
AI を使って候補者を絞り込むことは不可能ではありませんが、現時点では相応のリスクが伴うことを十分認識しておく必要があります。
もう 1 つ、採用や評価に関わる業務において意識すべきことがあります。それは「AI は人の鏡である」ということです。AI は無から有を生み出すことはありません。人が与えたデータを基にパターンを学習し、それにならって結果を出力するのが AI の基本原理です。したがって、AI が出力した結果が極端に偏っていたり、大きな誤りがあったりする場合には、もともと人間側が与えたデータに原因がある可能性もあります。
現在在籍している社員のデータを基にして、生成 AI による役職・候補者マッチングシステムを作ったケースを想定してみましょう。生成 AI がレコメンドする候補者が特定の属性に偏っているとすれば、それは生成 AI の回答精度ではなく、今の会社の組織構成に問題があるのかもしれません。まずは自社の状況を正視し、問題点を探るきっかけとするのがスマートな AI 活用方法でしょう。
［日経 BOOK プラス 2025 年 1 月 8 日付の記事を転載］
