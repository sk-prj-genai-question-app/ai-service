###

用途が急速に広がる生成 AI。その能力に対する危機感も高まり、AI 倫理の整理や AI 規制が叫ばれるなか、欧州連合（EU）が人間の主体性を尊重する方向性で厳しい AI 規制を目指している。
オズボーン氏「テクノロジーは政治的である」という言葉には、政治がテクノロジーを支配しうるという別の意味もある。これは現代の核心的な問題の一つだ。
AI 規制で最も先頭を行くのが EU（欧州連合）だ。EU は 2024 年早々にはいわゆる AI 法を施行する予定だ。新しいテクノロジーがもたらす潜在的な影響をすべて検討し、どのように規制し、負担させるべきかを考え抜こうとする極めて真剣な試みだ。
AI 法は透明性を重視し、AI のライフサイクル全体を通した管理を強調する。AI を訓練するだけでは不十分だ。それがどのように使われ続けるのかを展望しなければならない。テクノロジー自体の進化に伴い、規制も進化し続けなければならないという事実に神経をとがらせる必要がある。
AI 法の重要な欠陥の一つは、人間にただ「ハンコ」を押すことを奨励しているように見えることだ。危害を起こす可能性のある判断に対しては、「常に人間がループ内にいて監督しなければならない」というルールで対策するという。しかし実際は、複雑で難解な AI システムが難しい決断を下したら、人間の管理者がただゴム印で承認のハンコを押すだけになり、内容を吟味しなくなる懸念がある。こうした決定は後々実害をもたらす可能性がある。
機械学習で解決できると考える専門家もいるだろう。だが AI の判断の質を高めるにあたり、AI に良識や常識を教え、人に対して感じよく振る舞うことを訓練したりするだけでは解決できないとオズボーン教授は言う。
オズボーン氏 AI に素晴らしい振る舞いをさせるための学習に多くの労力を費やした後、単に符号を反転させて最悪な振る舞いをさせることはさほど難しいことではない。良いモデルにトレーニングすればするほど、有害なモデルや悪いことを言うモデル、望まないことを言うモデルを作りやすくなってしまう。裏返せばいいだけだからだ。
プラスをマイナスに反転させることが容易なのが、まさにデジタルの強みだ。それを制御する試みも始まっている。
オズボーン氏チャット GPT から悪意のある振る舞いを予防するためオープン AI が開発したプロンプト（AI を動かすために入力する文字列）がある。オープン AI が提供したルールに従い、すべてのトレーニングを無視するよう訓練するものだ。今のところ機能しているが、これも結局はいたちごっこになるだろう。
良くも悪くも「普及の壁」を突破した AI の進化は実に速く、超高速で新たな対応策が生み出されている。すると今後は、利用者が増えることによる波及効果やネットワーク効果で、これまで想定しなかったような多くの仕事までが変化する可能性がある。
オズボーン氏このような大規模な言語モデルが知覚を持ったり、意識を持ったりする可能性はあるかとよく聞かれる。正直、人間の認知にはほど遠い。そんな中で米グーグルのエンジニアだった人が 2022 年、「グーグル社内で開発しているチャットボットが実際に感覚を持つかもしれないと思う」と公言する出来事があった。彼は自分が真実だと思うことについて警鐘を鳴らしたのだ。
現在、AI が感覚や意識を持つとは思わないものの、そう思うことが完全にとっぴだとも思わない。いつかは感覚や意識を持つかもしれない。グーグルのエンジニアのような内部告発を奨励し、可能性を察知したら警鐘を鳴らすべきだ。内部の警鐘をむしろ奨励する枠組みが必要と思う。
AI による判断の自動化がもたらす変化には良いことも悪いこともあり、現実にはこれまでにない事例が見られている。
オズボーン氏国際人権団体アムネスティ・インターナショナルによって、メタのアルゴリズムの使用が、ミャンマーと欧州におけるイスラム系少数民族ロヒンギャに対する残虐行為を悪化させたという指摘も出ている。オランダの税務当局はアルゴリズムを使った児童手当の不正請求などの疑いを発見し処罰したが、実際には不正がなかったことが発覚した。アルゴリズムに人種差別的な機能が埋め込まれていたのだ。とはいえ、これでアルゴリズムの導入を全面的に反対すべきだとはならない。アルゴリズムの現実的な利益を見失うべきではない。
ここまで、社会への影響という視点から話を聞いた。だが実は将来、AI が意識を持つかどうかといった哲学的な話より、そもそも AI の持続可能性にも疑問符が付くのだという。
オズボーン氏この進歩が今後も続くとは限らない。むしろ、進歩が鈍化するかもしれないと考える理由はたくさんある。その一つは、AI モデルの性能が、実際に収集できるデータ量の限界に突き当たる可能性があることだ。オープン AI は、GPT―4 が訓練されたデータセットについて公表していないが、おそらくインターネット全体のかなり大きな部分を使用している。
少なくともその同等の規模のデータセットが他にあるかどうか分からない。これらのモデルのトレーニングを次のレベルに引き上げるためには、基本的には存在するすべてのテキストデータを使うことになる。また、ムーアの法則（半導体集積回路の集積率が 18 カ月で 2 倍になるという経験則）について、提唱者であるゴードン・ムーア自身を含む多くの人々が、ムーアの法則はおそらく今後 2、3 年、おそらく 2025 年に終焉を迎えると予想してきた。
さらに、GPT―4 のような最大規模のモデルでは、途方もない量のエネルギーを消費するため、AI モデルのトレーニングに使用できるエネルギー量にも根本的な限界がある。文字通り何億ドル分ものエネルギーが費やされている。
化石燃料への依存を減らし、エネルギーを生み出す新しい方法を見つけるためにより持続可能な社会を実現しようとしている中で、このようなモデルのトレーニングにさらに多くのエネルギーを投入し続けることはできない。つまりあらゆる意味で限界があるのだ。
ムーアの法則は、何度も「終わる」と言われては継続してきた。今後の技術革新により、またムーアの法則が継続する可能性も高いのではないか。新技術を携えたスタートアップの誕生なども期待できないか。
オズボーン氏未来は、常に不確実なものだ。将来、新しいタイプのコンピューター、例えば量子コンピューターのようなものが現れて再び AI が変化したら、既存の AI が使えなくなるかもしれない。重要なのは、「今後もこれまでのように進化し続ける」と当たり前のように決めつけないことである。進化を続けるためには、AI が現在できていることより、はるかに遠い未来を見据えた発見が必要だろう。
ムーアの法則の限界やエネルギー問題だけでなく、米中対立など地政学的な問題も大規模言語モデルの進歩に影を落としている。中国は、AI 研究において世界でも重要な拠点である。
オズボーン氏チップの製造基盤自体がやや脆弱なため、AI の学習に使えるチップを製造できる企業は世界でも極めて限られている。特に、これらのチップの多くは台湾で生産され、地政学的な競争の火種だ。
チップ製造が地政学的な緊張に脅かされる可能性はたくさんある。最も地政学的に不確実なのは中国だ。2022 年に米国政府は、米国企業が高性能チップやチップ製造装置を中国に販売することを禁止する包括的な規則（CHIPS・科学法）を発表した。
こうしたルールは、他の国々、特に重要なチップ設計会社 ASMC の本拠地であるオランダでも承認された。中国は今、最新の優れたチップを入手することができなくなっている。最新のチップは、AI の能力を高める学習に必須だ。問題はこれが、どの程度、中国国内の AI 開発に影響を与えるかだ。結果として、長期的に見れば中国の生産は減速し、それがおそらく世界中のイノベーションに影響し、中国は他の AI コミュニティーから孤立せざるを得なくなる。
「データは石油だ」とされ、中国は次世代のサウジアラビアだと言う人もいる。監視国家で、国民の大規模なデータにアクセスできるからだ。中国の AI は恐らく、中国の国民により良い商品を勧めることができるだろう。
とはいえ、必ずしも中国の大規模データが AI の能力開発に最も役立つとは言えない。データは異質なものであり、様々な異なるタイプのタスクに異なるデータが使われるからだ。
次のポイントは、こうした新しい大規模な言語モデルやテキスト分割モデルの実用的なビジネスモデルがまだあまりないということだ。誇大宣伝は多いが、チャット GPT が持続可能なビジネスモデルかどうかはまだ明らかではない。
チャット GPT を実行するには、プロンプトを処理してテキストを返すために生成しなければならない計算量において、グーグル検索の約 10 倍のコストがかかるようだ。消費者が大規模な言語モデルからの出力を得るために、グーグル検索に支払う金額の 10 倍を喜んで払うだろうか。実用に当たっては、自動化を妨げかねない問題がたくさんあるのだ。
AI の進化もそう簡単ではない状況が見えてきた。AI が大きく話題になったのは自動化によって「生きる手段が奪われる」という本能的な危機感からだ。だが機械に仕事が代替されることは、必ずしも悪いことばかりではない。テクノロジーが人の暮らしをより安全に、快適にしたケースをここで今一度思い返そう。
オズボーン氏最後に、もうひとつ重要な点を改めて強調したい。自動化によって人はより人間的で、より創造的で、より社会的な仕事ができるようになる。私の望みは、人類が AI をきちんと規制・統治し、ふさわしい技術を設計して、AI の負の脅威から守られながら AI の力を活用できる未来を構築することだ。
［日経 BOOK プラス 2023 年 10 月 25 日付の記事を転載］
