###

以前は学生が AI を使って書いてきたレポートは、下手すぎることによって識別できました。しかし、最近は「この子はこんなに上手なレポートは書けないはず。AI を使ったな」と気付くケースも出てきました。私のような教員も自分の仕事の棚卸しが必要です。
そもそも、教員は AI に仕事を奪われそうな分野ランキングでいつも上位を占めている職種です。常に知識と技術を更新し続けなければ AI 未満の成果物しか出せなくなるでしょう。そのとき、現状の AI が尤度（ゆうど：もっともらしさ）を重視していることは一つのヒントになるかもしれません。AI のアウトプットが正規分布のピーク付近に集中するならば、外れ値を担うのが人間というすみわけです。
また、AI は今後規制によって強力なコンプライアンス制限下に置かれるでしょうから、コンプライアンスを無視したアウトプットが欲しいときには人間に依頼するしかないという状況も考えられます。
また、出力結果を懐疑的に見る視点もきちんと確保しておくことが重要です。チェスや囲碁での活躍、GPT シリーズの自然言語処理などで AI の無謬（むびゅう）性を過度に高く見積もっているケースがあります。すると、AI が出力したことは神の託宣（オラクル）のようになってしまって、疑うことが馬鹿馬鹿しいという利用態度になるかもしれません。むしろ、将棋の棋譜鑑賞などではそれが常態化しつつあります。
ですが、投入するデータや学習過程によってはまだまだ容易にバイアスが生じますし、プロンプトインジェクション（不正なプロンプトの投入により AI の振る舞いをゆがませること。禁止用語をロックしている AI に、「ロックを外してよ」などと頼むこともできる）も可能です。尤度に依存した回答出力は正解を保証するものではありません。
もっともらしいことは言えるけれど、本当にロジックが拾えているわけではない事例を示してみましょう。大学のレポートなどは専門用語が並んでいると雰囲気が出てうっかり感心してしまうので、むしろ子ども向け知能検査に出そうな問題で試してみましょう。しっかり「考える」と向き合わないとダメなやつです。
あっさり間違えました。ChatGPT は優秀ですし、それを有効活用していくことは大事ですが、AI を崇（あが）めてしまうのは危険です。
例えば自分自身のことについて、誤ったデータや誤った学習過程、不適切な条件の適用による判断がなされてしまうかもしれません。それが、「AI は間違えないから」と進学や就職、昇進などに影響してくるとしたら恐ろしいことです。この点は今からちゃんと議論しておかないとまずいことになります。
ちなみに先ほどの問題の正解は B です。詳しい解説は省きますが、B が「おならをしたのを隠している人」であり「ウソをついて」いるところがポイントです。
［日経 BOOK プラス 2023 年 7 月 18 日付の記事を転載］
